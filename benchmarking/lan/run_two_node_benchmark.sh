#!/usr/bin/env bash
# Copyright 2026 Siddharth Viswanathan
# This file was fully generated by Codex and may contain modifications by Siddharth Viswanathan as of 2026.
# SPDX-License-Identifier: Apache-2.0

set -euo pipefail

usage() {
  cat <<'EOF'
Usage:
  run_two_node_benchmark.sh --remote-url URL [options]

This script is run on the "driver" node (for example Ubuntu) and benchmarks
communication to a peer node (for example MacBook) over LAN.

Benchmark groups:
  1) sync_rtt: elapsed time of `vcs sync --peer <remote>`
  2) replication_latency: time from local `vcs op append` until remote summary
     reflects the appended sequence for the local author

Options:
  --remote-url URL      Remote daemon base URL (required), e.g. http://192.168.1.24:8787
  --repo PATH           Repository root on this machine (default: current directory)
  --vcs-bin PATH        Local vcs binary (default: <repo>/vcs)
  --iterations N        Measured iterations per benchmark group (default: 40)
  --warmup N            Warmup iterations per benchmark group (default: 8)
  --poll-ms N           Poll interval while waiting for replication (default: 25)
  --timeout-ms N        Timeout per replication sample (default: 10000)
  --mode MODE           replication mode: manual-sync or passive-daemon (default: manual-sync)
  --sync-limit N        Passed to vcs sync --limit (default: 256)
  --sync-rounds N       Passed to vcs sync --rounds (default: 6)
  --tag NAME            Optional tag suffix for result directory
  --out-root PATH       Output root (default: benchmarking/results/lan)
  -h, --help            Show this help

Examples:
  ./benchmarking/lan/run_two_node_benchmark.sh \
    --remote-url http://192.168.1.24:8787 \
    --iterations 50 --warmup 10 --mode manual-sync

  ./benchmarking/lan/run_two_node_benchmark.sh \
    --remote-url http://192.168.1.24:8787 \
    --mode passive-daemon --timeout-ms 20000
EOF
}

require_command() {
  if ! command -v "$1" >/dev/null 2>&1; then
    echo "error: required command not found: $1" >&2
    exit 1
  fi
}

now_ns() {
  local value
  value="$(date +%s%N 2>/dev/null || true)"
  if [[ "$value" =~ ^[0-9]+$ ]]; then
    printf '%s\n' "$value"
    return
  fi
  if [[ -n "${EPOCHREALTIME:-}" ]]; then
    local sec frac
    sec="${EPOCHREALTIME%.*}"
    frac="${EPOCHREALTIME#*.}"
    frac="${frac}000000000"
    frac="${frac:0:9}"
    printf '%s%s\n' "$sec" "$frac"
    return
  fi
  printf '%s000000000\n' "$(date +%s)"
}

elapsed_ms() {
  local start_ns="$1"
  local end_ns="$2"
  awk -v s="$start_ns" -v e="$end_ns" 'BEGIN { printf "%.3f", (e - s) / 1000000.0 }'
}

csv_escape() {
  local raw="$1"
  raw="${raw//\"/\"\"}"
  printf '"%s"' "$raw"
}

json_escape() {
  local raw="$1"
  raw="${raw//\\/\\\\}"
  raw="${raw//\"/\\\"}"
  raw="${raw//$'\n'/\\n}"
  raw="${raw//$'\r'/\\r}"
  raw="${raw//$'\t'/\\t}"
  printf '%s' "$raw"
}

json_number_or_null() {
  local raw="$1"
  if [[ -z "$raw" || "$raw" == "n/a" ]]; then
    printf 'null'
  else
    printf '%s' "$raw"
  fi
}

remote_summary_seq() {
  local remote_url="$1"
  local author_id="$2"
  local response compact escaped_author pattern match
  response="$(curl -fsS "${remote_url%/}/v1/node")"
  compact="$(printf '%s' "$response" | tr -d '\r\n')"
  escaped_author="$(printf '%s' "$author_id" | sed 's/[][\\.^$*+?{}|()]/\\&/g')"
  pattern="\"${escaped_author}\"[[:space:]]*:[[:space:]]*[0-9][0-9]*"
  match="$(printf '%s' "$compact" | grep -oE "$pattern" | head -n1 || true)"
  if [[ -z "$match" ]]; then
    printf '0\n'
    return
  fi
  printf '%s' "$match" | sed -E 's/.*:[[:space:]]*([0-9]+).*/\1/'
}

parse_append_output_field() {
  local output="$1"
  local field="$2"
  case "$field" in
    author)
      printf '%s\n' "$output" | sed -n 's/.* author=\([^ ]*\).*/\1/p' | tail -n1
      ;;
    seq)
      printf '%s\n' "$output" | sed -n 's/.* seq=\([0-9][0-9]*\).*/\1/p' | tail -n1
      ;;
    *)
      return 1
      ;;
  esac
}

compute_stats_from_csv() {
  local csv_path="$1"
  local prefix="$2"
  local failures values stats key value

  failures="$(awk -F',' 'NR > 1 && $1 == "measured" && $3 != "ok" { c++ } END { print c + 0 }' "$csv_path")"
  values="$(awk -F',' 'NR > 1 && $1 == "measured" && $3 == "ok" { print $4 + 0 }' "$csv_path" | sort -n)"
  stats="$(
    printf '%s\n' "$values" | awk '
      BEGIN {
        n = 0
        sum = 0
        sumsq = 0
      }
      NF > 0 {
        v = $1 + 0
        vals[++n] = v
        sum += v
        sumsq += v * v
      }
      END {
        if (n == 0) {
          print "count=0"
          print "mean=n/a"
          print "median=n/a"
          print "p95=n/a"
          print "stddev=n/a"
          print "min=n/a"
          print "max=n/a"
          exit
        }

        mean = sum / n
        if (n % 2 == 1) {
          median = vals[(n + 1) / 2]
        } else {
          median = (vals[n / 2] + vals[n / 2 + 1]) / 2
        }

        p95_idx = int((95 * n + 99) / 100)
        if (p95_idx < 1) {
          p95_idx = 1
        }
        if (p95_idx > n) {
          p95_idx = n
        }
        p95 = vals[p95_idx]

        var = (sumsq / n) - (mean * mean)
        if (var < 0) {
          var = 0
        }
        stddev = sqrt(var)

        printf "count=%d\n", n
        printf "mean=%.3f\n", mean
        printf "median=%.3f\n", median
        printf "p95=%.3f\n", p95
        printf "stddev=%.3f\n", stddev
        printf "min=%.3f\n", vals[1]
        printf "max=%.3f\n", vals[n]
      }
    '
  )"

  eval "${prefix}_failures=\"${failures}\""
  while IFS='=' read -r key value; do
    [[ -z "${key:-}" ]] && continue
    eval "${prefix}_${key}=\"${value}\""
  done <<< "$stats"
}

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DEFAULT_OUT_ROOT="$SCRIPT_DIR/../results/lan"

REPO_PATH="$(pwd)"
VCS_BIN=""
REMOTE_URL=""
ITERATIONS=40
WARMUP=8
POLL_MS=25
TIMEOUT_MS=10000
MODE="manual-sync"
SYNC_LIMIT=256
SYNC_ROUNDS=6
RUN_TAG=""
OUT_ROOT="$DEFAULT_OUT_ROOT"

while [[ $# -gt 0 ]]; do
  case "$1" in
    --remote-url)
      REMOTE_URL="$2"
      shift 2
      ;;
    --repo)
      REPO_PATH="$2"
      shift 2
      ;;
    --vcs-bin)
      VCS_BIN="$2"
      shift 2
      ;;
    --iterations)
      ITERATIONS="$2"
      shift 2
      ;;
    --warmup)
      WARMUP="$2"
      shift 2
      ;;
    --poll-ms)
      POLL_MS="$2"
      shift 2
      ;;
    --timeout-ms)
      TIMEOUT_MS="$2"
      shift 2
      ;;
    --mode)
      MODE="$2"
      shift 2
      ;;
    --sync-limit)
      SYNC_LIMIT="$2"
      shift 2
      ;;
    --sync-rounds)
      SYNC_ROUNDS="$2"
      shift 2
      ;;
    --tag)
      RUN_TAG="$2"
      shift 2
      ;;
    --out-root)
      OUT_ROOT="$2"
      shift 2
      ;;
    -h|--help)
      usage
      exit 0
      ;;
    *)
      echo "error: unknown argument: $1" >&2
      usage
      exit 1
      ;;
  esac
done

if [[ -z "$REMOTE_URL" ]]; then
  echo "error: --remote-url is required" >&2
  usage
  exit 1
fi

if [[ -z "$VCS_BIN" ]]; then
  VCS_BIN="$REPO_PATH/vcs"
fi

if [[ "$MODE" != "manual-sync" && "$MODE" != "passive-daemon" ]]; then
  echo "error: --mode must be one of: manual-sync, passive-daemon" >&2
  exit 1
fi

if [[ ! -d "$REPO_PATH/.git" ]]; then
  echo "error: --repo must point to a git repository root: $REPO_PATH" >&2
  exit 1
fi
if [[ ! -x "$VCS_BIN" ]]; then
  echo "error: vcs binary is not executable: $VCS_BIN" >&2
  exit 1
fi

require_command curl
require_command grep
require_command sort
require_command awk
require_command sed
require_command tr

# Validate connectivity to remote daemon before writing results.
curl -fsS "${REMOTE_URL%/}/v1/node" >/dev/null

TIMESTAMP_UTC="$(date -u +"%Y%m%dT%H%M%SZ")"
if [[ -n "$RUN_TAG" ]]; then
  RUN_DIR="$OUT_ROOT/$TIMESTAMP_UTC-$RUN_TAG"
else
  RUN_DIR="$OUT_ROOT/$TIMESTAMP_UTC"
fi
mkdir -p "$RUN_DIR"

SYNC_CSV="$RUN_DIR/sync_rtt.csv"
REPL_CSV="$RUN_DIR/replication_latency.csv"
SUMMARY_JSON="$RUN_DIR/summary.json"
SUMMARY_MD="$RUN_DIR/summary.md"

POLL_SLEEP_SECONDS="$(awk -v ms="$POLL_MS" 'BEGIN { if (ms < 1) ms = 1; printf "%.3f", ms / 1000.0 }')"

echo "phase,iteration,status,elapsed_ms,error" >"$SYNC_CSV"
echo "phase,iteration,status,elapsed_ms,author,expected_seq,observed_seq,polls,error" >"$REPL_CSV"

echo "LAN benchmark configuration:"
echo "  repo:         $REPO_PATH"
echo "  vcs-bin:      $VCS_BIN"
echo "  remote-url:   $REMOTE_URL"
echo "  mode:         $MODE"
echo "  iterations:   $ITERATIONS"
echo "  warmup:       $WARMUP"
echo "  poll-ms:      $POLL_MS"
echo "  timeout-ms:   $TIMEOUT_MS"
echo "  sync-limit:   $SYNC_LIMIT"
echo "  sync-rounds:  $SYNC_ROUNDS"
echo "  output-dir:   $RUN_DIR"
echo

TOTAL_RUNS=$((ITERATIONS + WARMUP))

echo "Running sync RTT benchmark..."
for ((i = 1; i <= TOTAL_RUNS; i++)); do
  phase="warmup"
  if ((i > WARMUP)); then
    phase="measured"
  fi

  start_ns="$(now_ns)"
  sync_err=""
  if ! sync_output="$(cd "$REPO_PATH" && "$VCS_BIN" sync --peer "$REMOTE_URL" --limit "$SYNC_LIMIT" --rounds "$SYNC_ROUNDS" 2>&1)"; then
    sync_err="$sync_output"
    sync_status="error"
  else
    sync_status="ok"
  fi
  end_ns="$(now_ns)"
  ms="$(elapsed_ms "$start_ns" "$end_ns")"

  printf '%s,%d,%s,%s,%s\n' \
    "$phase" \
    "$i" \
    "$sync_status" \
    "$ms" \
    "$(csv_escape "$sync_err")" >>"$SYNC_CSV"
done

echo "Running replication latency benchmark..."
for ((i = 1; i <= TOTAL_RUNS; i++)); do
  phase="warmup"
  if ((i > WARMUP)); then
    phase="measured"
  fi

  sent_ns="$(now_ns)"
  payload="{\"benchmark\":\"lan.replication\",\"iteration\":$i,\"sent_unix_ns\":$sent_ns}"

  append_err=""
  if ! append_output="$(cd "$REPO_PATH" && "$VCS_BIN" op append --type bench.lan.replication --data "$payload" 2>&1)"; then
    append_err="$append_output"
    printf '%s,%d,%s,%s,%s,%s,%s,%s,%s\n' \
      "$phase" \
      "$i" \
      "error" \
      "0.000" \
      "$(csv_escape "")" \
      "0" \
      "0" \
      "0" \
      "$(csv_escape "op append failed: $append_err")" >>"$REPL_CSV"
    continue
  fi

  author_id="$(parse_append_output_field "$append_output" "author")"
  expected_seq="$(parse_append_output_field "$append_output" "seq")"
  if [[ -z "$author_id" || -z "$expected_seq" ]]; then
    printf '%s,%d,%s,%s,%s,%s,%s,%s,%s\n' \
      "$phase" \
      "$i" \
      "error" \
      "0.000" \
      "$(csv_escape "$author_id")" \
      "${expected_seq:-0}" \
      "0" \
      "0" \
      "$(csv_escape "unable to parse author/seq from op append output: $append_output")" >>"$REPL_CSV"
    continue
  fi

  start_ns="$(now_ns)"
  replication_err=""
  if [[ "$MODE" == "manual-sync" ]]; then
    if ! manual_sync_output="$(cd "$REPO_PATH" && "$VCS_BIN" sync --peer "$REMOTE_URL" --limit "$SYNC_LIMIT" --rounds "$SYNC_ROUNDS" 2>&1)"; then
      replication_err="manual sync failed: $manual_sync_output"
    fi
  fi

  timeout_ns=$((start_ns + TIMEOUT_MS * 1000000))
  polls=0
  observed_seq=0
  status="timeout"

  while true; do
    seq_candidate="$(remote_summary_seq "$REMOTE_URL" "$author_id" || true)"
    if [[ "$seq_candidate" =~ ^[0-9]+$ ]]; then
      observed_seq="$seq_candidate"
      if ((observed_seq >= expected_seq)); then
        status="ok"
        break
      fi
    fi

    now="$(now_ns)"
    if ((now >= timeout_ns)); then
      break
    fi

    polls=$((polls + 1))
    sleep "$POLL_SLEEP_SECONDS"
  done

  end_ns="$(now_ns)"
  ms="$(elapsed_ms "$start_ns" "$end_ns")"
  if [[ "$status" != "ok" && -z "$replication_err" ]]; then
    replication_err="remote summary for $author_id did not reach seq $expected_seq before timeout"
  fi

  printf '%s,%d,%s,%s,%s,%s,%s,%d,%s\n' \
    "$phase" \
    "$i" \
    "$status" \
    "$ms" \
    "$(csv_escape "$author_id")" \
    "$expected_seq" \
    "$observed_seq" \
    "$polls" \
    "$(csv_escape "$replication_err")" >>"$REPL_CSV"
done

compute_stats_from_csv "$SYNC_CSV" "sync"
compute_stats_from_csv "$REPL_CSV" "repl"

cat >"$SUMMARY_JSON" <<EOF
{
  "timestamp_utc": "$(json_escape "$TIMESTAMP_UTC")",
  "remote_url": "$(json_escape "$REMOTE_URL")",
  "mode": "$(json_escape "$MODE")",
  "iterations": $ITERATIONS,
  "warmup": $WARMUP,
  "poll_ms": $POLL_MS,
  "timeout_ms": $TIMEOUT_MS,
  "sync_limit": $SYNC_LIMIT,
  "sync_rounds": $SYNC_ROUNDS,
  "repo_path": "$(json_escape "$REPO_PATH")",
  "vcs_bin": "$(json_escape "$VCS_BIN")",
  "benchmarks": {
    "sync_rtt": {
      "stats": {
        "count": $sync_count,
        "mean_ms": $(json_number_or_null "$sync_mean"),
        "median_ms": $(json_number_or_null "$sync_median"),
        "p95_ms": $(json_number_or_null "$sync_p95"),
        "stddev_ms": $(json_number_or_null "$sync_stddev"),
        "min_ms": $(json_number_or_null "$sync_min"),
        "max_ms": $(json_number_or_null "$sync_max")
      },
      "measured_failures": $sync_failures
    },
    "replication_latency": {
      "stats": {
        "count": $repl_count,
        "mean_ms": $(json_number_or_null "$repl_mean"),
        "median_ms": $(json_number_or_null "$repl_median"),
        "p95_ms": $(json_number_or_null "$repl_p95"),
        "stddev_ms": $(json_number_or_null "$repl_stddev"),
        "min_ms": $(json_number_or_null "$repl_min"),
        "max_ms": $(json_number_or_null "$repl_max")
      },
      "measured_failures": $repl_failures
    }
  }
}
EOF

cat >"$SUMMARY_MD" <<EOF
# Two-Node LAN Benchmark Summary

- Timestamp (UTC): \`$TIMESTAMP_UTC\`
- Remote URL: \`$REMOTE_URL\`
- Mode: \`$MODE\`
- Iterations: \`$ITERATIONS\` (warmup \`$WARMUP\`)
- Poll interval: \`$POLL_MS ms\`
- Timeout: \`$TIMEOUT_MS ms\`
- Sync params: \`limit=$SYNC_LIMIT\`, \`rounds=$SYNC_ROUNDS\`

## Results

| Benchmark | ok samples | failures | mean (ms) | median (ms) | p95 (ms) | stddev (ms) | min (ms) | max (ms) |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| sync_rtt | $sync_count | $sync_failures | $sync_mean | $sync_median | $sync_p95 | $sync_stddev | $sync_min | $sync_max |
| replication_latency | $repl_count | $repl_failures | $repl_mean | $repl_median | $repl_p95 | $repl_stddev | $repl_min | $repl_max |

## Artifacts

- Raw sync data: \`$SYNC_CSV\`
- Raw replication data: \`$REPL_CSV\`
- JSON summary: \`$SUMMARY_JSON\`
EOF

echo
echo "Benchmark complete."
echo "  sync data:         $SYNC_CSV"
echo "  replication data:  $REPL_CSV"
echo "  summary (json):    $SUMMARY_JSON"
echo "  summary (md):      $SUMMARY_MD"
